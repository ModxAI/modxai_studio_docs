# 模型训练

> v1.0.0
> 2025-12

本文介绍 ModxAI Studio 中**模型训练**功能的使用方法，帮助您完成从数据准备到模型输出的完整训练流程。

## 目录

- [环境要求](#环境要求)
- [功能概述](#功能概述)
- [界面布局](#界面布局)
- [功能模块](#功能模块)
- [训练任务机制](#训练任务机制)
- [配额消耗规则](#配额消耗规则)
- [训练参数体系](#训练参数体系)
- [参数模板机制](#参数模板机制)
- [后续文档](#后续文档)

---

## 环境要求

### 基础要求

| 需求 | 说明 |
|------|------|
| 运行环境 | 需在**设置**中安装 GPU 或 CPU 依赖环境 |
| 显存 | LoRA 微调最低 4GB，建议 8GB 以上 |
| 磁盘空间 | 检查点和日志需要足够存储空间 |

### 环境安装

在训练准备页面，点击"环境配置"可安装训练所需的 Python 依赖：

- **GPU 环境**：安装 PyTorch CUDA 版本及相关训练库
- **CPU 环境**：安装 PyTorch CPU 版本（训练速度较慢）

### 硬件推荐

| 模型规模 | 显存需求（LoRA）| 显存需求（全量）|
|----------|----------------|----------------|
| 1B 以下 | 4GB | 16GB |
| 1-3B | 6GB | 24GB |
| 3-7B | 8GB | 40GB |
| 7-14B | 12GB | 80GB |

---

## 功能概述

模型训练模块是 ModxAI Studio 的核心功能之一，提供从训练配置到模型输出的完整工作流。主要特点：

- **多训练类型支持**：支持 SFT（监督微调）和预训练两种训练方式
- **LoRA 高效微调**：SFT 默认使用 LoRA 技术，大幅降低显存需求
- **实时监控**：可视化展示训练进度、损失曲线、学习率变化等核心指标
- **检查点管理**：自动保存训练检查点，支持断点续训
- **模型评估**：对多个检查点进行综合评估，自动推荐最优检查点
- **交互式测试**：选择检查点进行实时推理测试，验证模型回答质量
- **一键打包**：将训练产物导出为 GGUF 格式，可直接用于推理部署

---

## 界面布局

训练模块采用标签页式布局，包含五个功能页面：

| 标签 | 图标 | 说明 |
|------|------|------|
| **准备** | 滑块 | 创建训练任务、配置训练参数 |
| **监控** | 折线图 | 查看训练进度和实时指标 |
| **评估** | 饼图 | 对检查点进行质量评估 |
| **测试** | 发送 | 交互式测试检查点效果 |
| **打包** | 保存 | 导出模型为 GGUF 格式 |

---

## 功能模块

### 准备模块

准备模块用于创建和配置训练任务：

| 功能 | 说明 |
|------|------|
| 训练类型选择 | SFT（监督微调）或预训练 |
| 数据文件配置 | 训练数据、评估数据文件路径 |
| 模型路径设置 | 基础模型路径、分词器路径 |
| 输出目录指定 | 检查点、日志等训练产物存储位置 |
| 参数模板选择 | 快速加载预设参数组合 |
| 参数精调 | 可逐项调整各类训练超参数 |

### 监控模块

监控模块提供两种工作模式：

**实时监控模式**：
- 当有训练任务正在运行时自动进入
- 实时显示当前步数、总步数、进度百分比、预计剩余时间
- 实时绘制 Loss、Perplexity、Learning Rate、Gradient Norm 等曲线
- 显示实时训练日志

**历史回顾模式**：
- 选择已完成的训练任务查看历史数据
- 加载并展示完整的训练曲线
- 回顾训练日志和检查点记录

### 评估模块

评估模块用于评估多个检查点的模型质量：

| 功能 | 说明 |
|------|------|
| 检查点选择 | 支持选择 2 个及以上检查点进行对比评估 |
| 评估数据集 | 使用采样数据测试模型生成能力 |
| 综合评分 | 基于困惑度、语义相似度、连贯性、覆盖率等多维度打分 |
| 结果输出 | 生成详细评估报告和 CSV 结果文件到输出目录 |
| 最优推荐 | 自动识别综合得分最高的检查点 |

评估结果文件存储在任务输出目录的目录下。

### 测试模块

测试模块提供交互式推理测试：

| 功能 | 说明 |
|------|------|
| 检查点加载 | 选择任意检查点进行测试 |
| 参数调节 | 温度、Top-P、Top-K、重复惩罚等推理参数 |
| 实时对话 | 向模型发送消息，实时查看回复 |
| 系统提示词 | 可自定义系统提示词测试不同角色效果 |

### 打包模块

打包模块用于导出可部署的模型：

| 功能 | 说明 |
|------|------|
| 检查点选择 | 选择要打包的 LoRA 检查点 |
| 量化类型 | 支持多种量化格式（Q2_K 至 Q8_0、F16 等）|
| 合并 LoRA | 可选择是否将 LoRA 权重合并到基础模型 |
| 输出格式 | 导出为 GGUF 格式，可直接用于推理 |

---

## 训练任务机制

### 任务生命周期

训练任务按以下状态流转：

```
pending → running → completed
                 ↘ stopped（用户主动停止）
                 ↘ failed（训练异常退出）
```

| 状态 | 说明 |
|------|------|
| `pending` | 任务已创建，等待启动 |
| `running` | 训练进行中 |
| `stopping` | 正在停止（过渡状态）|
| `stopped` | 用户主动停止 |
| `completed` | 训练正常完成 |
| `failed` | 训练异常退出 |

### 任务 ID

每个训练任务创建时会生成唯一的任务 ID，用于：
- 关联训练日志
- 关联检查点记录
- 关联评估、测试、打包操作

### 相关数据表

训练模块涉及以下核心数据：

| 数据类型 | 说明 |
|----------|------|
| 训练任务 | 任务基本信息、状态、配置 |
| 任务参数 | 任务的具体训练参数值 |
| 训练日志 | 每步的 loss、lr、进度等指标 |
| 检查点记录 | 每个检查点的保存时间、步数、损失值 |

---

## 配额消耗规则

训练过程中的配额消耗与检查点保存相关：

### 消耗规则

- **每保存一个检查点，消耗 1 个训练配额**

### 影响因素

检查点保存数量受以下参数影响：

| 界面显示名称 | 说明 |
|-------------|------|
| 保存策略 | 按步数（steps）、按轮次（epoch）或不保存（no）|
| 保存步数 | 当策略为 steps 时，每隔多少步保存一次 |
| 最大保存检查点 | 超出此数量后自动删除旧检查点 |
| 保存间隔分钟 | 按时间间隔保存（分钟）|

### 配额预估

**示例**：训练总步数 1000 步，保存步数设为 100，则预计保存 10 个检查点，消耗 10 个配额。

### 查看配额

配额使用情况可在应用顶部状态栏查看，系统会在配额不足时发出警告通知。

---

## 训练参数体系

训练参数按功能分类组织，支持 SFT 和预训练两种模板类型。

> **参数名称说明**：下表中的"界面显示名称"列与应用界面中的参数标签一致，便于用户快速对照查找。

### 参数分类

| 分类 | 说明 | 关键参数 |
|------|------|----------|
| **data** | 数据配置 | 训练数据、评估数据、模型目录、分词器等 |
| **training** | 训练配置 | 批次大小、学习率、轮数、保存策略等 |
| **lora** | LoRA 配置 | 是否启用、r、alpha、dropout、目标模块 |
| **optimization** | 优化配置 | 混合精度（FP16/BF16/TF32）、梯度检查点 |
| **logging** | 日志配置 | 日志级别、记录步数 |
| **general** | 通用配置 | 随机种子 |

### 核心参数说明

**数据配置**：

| 界面显示名称 | 默认值 | 说明 |
|-------------|--------|------|
| 训练数据文件路径 | - | JSONL 格式的训练数据文件（必填）|
| (可选)评估数据文件路径 | - | JSONL 格式的评估数据文件 |
| 训练输出目录 | - | 检查点、日志等训练产物的存储位置（必填）|
| 训练模型目录 | - | **可训练模型的目录路径**（必填，见下方说明）|
| (可选)分词器路径 | - | 分词器目录路径，留空则使用模型自带分词器 |
| (可选)恢复训练检查点路径 | - | 从指定检查点继续训练 |
| 最大样本数 | 0 | 限制训练样本数量，0 表示不限制 |
| 评估集采样比例 | 0 | 从训练集划分的评估集比例（0-1）|

> ⚠️ **关于"训练模型目录"**：
> 
> 此参数需要指定**可训练模型**所在的目录，**不是**模型库中的 GGUF 推理模型。
> 
> - **正确格式**：HuggingFace 格式的模型目录，包含 `.safetensors` 权重文件和 `config.json` 配置文件
> - **错误格式**：`.gguf` 文件（仅用于推理，不可用于训练）
> 
> 请确保模型目录中包含以下必要文件：
> - `config.json` - 模型配置
> - `*.safetensors` - 模型权重文件
> - `tokenizer.json` 或 `tokenizer_config.json` - 分词器配置（可选，也可单独指定）

**训练配置**：

| 界面显示名称 | 默认值 | 说明 |
|-------------|--------|------|
| 批次大小 | 2 | 每步处理的样本数（1-128）|
| 梯度累积步数 | 4 | 累积多少步后更新权重（1-256）|
| 最大序列长度 | 512 | 输入序列的最大长度（128-8192）|
| 学习率 | 2e-4 | 模型参数更新的步长（1e-6 至 1e-1）|
| 优化器 | adamw_torch | 优化算法类型 |
| 学习率调度器 | cosine | 学习率变化策略 |
| 训练轮数 | 2 | 遍历完整数据集的次数（1-100）|
| 权重衰减 | 0.01 | 正则化参数，防止过拟合 |
| 预热比例 | 0.1 | 学习率预热阶段占比 |
| 最大梯度范数 | 1.0 | 梯度裁剪阈值 |
| 保存策略 | steps | 检查点保存策略：steps/epoch/no |
| 保存步数 | 100 | 每隔多少步保存一次检查点 |
| 评估策略 | no | 训练中评估策略：steps/epoch/no |
| 评估步数 | 100 | 每隔多少步进行一次评估 |
| 最大保存检查点 | 100 | 保留的最大检查点数量 |
| 早停步数 | 0 | 评估指标无改善时停止训练的步数阈值 |

**LoRA 配置**（SFT 默认启用）：

| 界面显示名称 | 默认值 | 说明 |
|-------------|--------|------|
| 使用LoRA微调 | true | 是否启用 LoRA 高效微调 |
| LoRA的r参数 | 16 | LoRA 秩，影响参数量（1-512）|
| LoRA的alpha参数 | 16 | LoRA 缩放因子 |
| LoRA的dropout | 0.0 | LoRA 层的 Dropout 比例（0-1）|
| LoRA目标模块 | ["q_proj", "v_proj"] | 应用 LoRA 的模型模块 |
| 训练后合并LoRA权重 | false | 训练完成后是否将 LoRA 合并到基础模型 |

**优化配置**：

| 界面显示名称 | 默认值 | 说明 |
|-------------|--------|------|
| 使用FP16混合精度 | true | 使用半精度浮点数加速训练 |
| 使用BF16混合精度(NVIDIA GPU) | false | 使用 BF16 格式（需 Ampere 及以上架构）|
| 使用TF32(NVIDIA GPU) | false | 使用 TensorFloat-32 格式 |
| 梯度检查点 | true | 以时间换空间，降低显存占用 |

**日志配置**：

| 界面显示名称 | 默认值 | 说明 |
|-------------|--------|------|
| 日志级别 | info | 日志详细程度：debug/info/warning/error |
| 日志记录步数 | 10 | 每隔多少步记录一次日志 |

**通用配置**：

| 界面显示名称 | 默认值 | 说明 |
|-------------|--------|------|
| 随机种子 | 42 | 控制随机性，确保可复现（0-999999）|

### SFT 与预训练差异

| 配置项 | SFT | 预训练 |
|--------|-----|--------|
| LoRA | 默认启用 | 默认禁用（隐藏 LoRA 配置区域）|
| 数据格式 | 对话格式 JSONL | 纯文本数据 |
| 目标 | 指令跟随能力 | 语言建模能力 |

---

## 参数模板机制

### 模板类型

系统支持两类参数模板：

| 类型 | 说明 |
|------|------|
| **默认模板** | 系统预置的基础参数配置，按训练类型区分（SFT/预训练）|
| **用户模板** | 用户自定义保存的参数配置 |

### 临时参数

创建训练任务时：

1. 首先加载选定的参数模板
2. 用户可在此基础上调整各项参数
3. 调整后的参数作为**任务参数**保存，与模板独立
4. 后续对模板的修改不影响已创建的任务

### 参数折叠

界面上的参数按重要性分层展示：

| 折叠组 | 说明 |
|--------|------|
| 无折叠 | 核心参数，默认展开显示 |
| `optional` | 可选参数，默认折叠 |
| `advanced` | 高级参数，默认折叠 |
| `optimization` | 优化相关参数，默认折叠 |
| `save` | 保存策略参数，默认折叠 |
| `eval` | 评估策略参数，默认折叠 |

---

## 后续文档

- [准备模块详解](./prepare.md) - 训练任务创建和参数配置指南
- [监控模块详解](./monitor.md) - 实时监控和历史回顾功能
- [评估模块详解](./evaluate.md) - 检查点评估和对比分析
- [测试模块详解](./test.md) - 交互式测试功能
- [打包模块详解](./package.md) - GGUF 导出和量化选项