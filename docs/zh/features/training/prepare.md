# 准备模块详解

> v1.0.0
> 2025-12

本文详细介绍 ModxAI Studio 训练模块中**准备**页面的功能和参数配置，帮助您正确设置训练任务。

## 目录

- [界面概览](#界面概览)
- [任务管理](#任务管理)
- [参数配置](#参数配置)
- [数据配置参数](#数据配置参数)
- [训练配置参数](#训练配置参数)
- [LoRA 配置参数](#lora-配置参数)
- [优化配置参数](#优化配置参数)
- [日志配置参数](#日志配置参数)
- [通用配置参数](#通用配置参数)
- [参数模板](#参数模板)
- [训练流程](#训练流程)

---

## 界面概览

准备模块界面分为左右两个区域：

| 区域 | 功能 |
|------|------|
| 左侧 - 基础配置 | 任务名称、配置模板、训练类型、训练设备、任务管理 |
| 右侧 - 操作控制 | 参数配置入口、开始/停止训练按钮、重置按钮 |

---

## 任务管理

### 任务名称自动生成

创建新任务时，系统会自动生成任务名称，格式为：

```
{训练类型}_{时间戳}
```

**示例**：`sft_20241201_143052`

- 训练类型：`sft` 或 `pretrain`
- 时间戳：`YYYYMMDD_HHmmss` 格式

您可以手动修改任务名称。

### 任务列表操作

| 操作 | 说明 |
|------|------|
| 新建任务 | 选择"新建任务"选项，创建全新的训练任务 |
| 选择已有任务 | 从下拉列表中选择已创建的任务，加载其参数配置 |
| 删除任务 | 点击任务右侧的删除图标，删除非运行中的任务 |

> ⚠️ **注意**：运行中的任务无法删除，需先停止训练。

### 任务状态

任务列表中会显示每个任务的状态标签：

| 状态 | 颜色 | 说明 |
|------|------|------|
| 等待中 | 蓝色 | 任务已创建，等待启动 |
| 运行中 | 绿色 | 训练正在进行 |
| 已完成 | 绿色 | 训练正常完成 |
| 已停止 | 橙色 | 用户主动停止 |
| 失败 | 红色 | 训练异常退出 |

---

## 参数配置

点击"配置参数"按钮打开参数配置抽屉，参数按功能分类为六个配置区域：

| 配置区域 | 英文名 | 说明 |
|----------|--------|------|
| 数据配置 | data | 训练数据、模型路径、输出目录等 |
| 训练配置 | training | 批次大小、学习率、保存策略等 |
| LoRA 配置 | lora | LoRA 相关参数（SFT 可见） |
| 优化配置 | optimization | 混合精度、梯度检查点等 |
| 日志配置 | logging | 日志级别、记录频率 |
| 通用配置 | general | 随机种子等 |

### 参数折叠

参数按重要性分层展示：

| 折叠组 | 说明 |
|--------|------|
| 常规参数 | 核心必要参数，默认展开 |
| 可选参数 | 非必须但常用的参数 |
| 高级参数 | 高级调优参数 |
| 优化参数 | 性能优化相关 |
| 保存参数 | 检查点保存策略 |
| 评估参数 | 训练中评估策略 |

---

## 数据配置参数

### 训练数据文件路径 / Training data file path

| 属性 | 值 |
|------|-----|
| 类型 | 文件路径 |
| 必填 | ✅ 是 |
| 默认值 | - |

**说明**：指定训练数据文件的完整路径。

**数据格式要求**：
- **SFT 训练**：JSONL 格式，每行一个 JSON 对象，包含对话数据
- **预训练**：纯文本或 JSONL 格式

**SFT 数据示例**：
```json
{"messages": [{"role": "user", "content": "你好"}, {"role": "assistant", "content": "你好！有什么可以帮助你的吗？"}]}
{"messages": [{"role": "user", "content": "介绍一下自己"}, {"role": "assistant", "content": "我是一个AI助手..."}]}
```

---

### (可选)评估数据文件路径 / (opt.) Evaluation data file path

| 属性 | 值 |
|------|-----|
| 类型 | 文件路径 |
| 必填 | ❌ 否 |
| 默认值 | - |
| 折叠组 | 可选参数 |

**说明**：指定评估数据文件路径，用于训练过程中的模型评估。

**使用场景**：
- 配合"评估策略"参数使用
- 监控训练过程中的模型表现
- 支持早停机制

**如果不提供评估文件**：
- 可以使用"评估集采样比例"从训练集中自动划分
- 或者将"评估策略"设为 `no` 跳过训练中评估

---

### 训练输出目录 / Training output directory

| 属性 | 值 |
|------|-----|
| 类型 | 目录路径 |
| 必填 | ✅ 是 |
| 默认值 | - |

**说明**：指定训练产物的输出目录。

**输出内容包括**：
- `checkpoint-{step}/` - 训练检查点目录
- 训练完成后的最终模型

**注意事项**：
- 确保目录有足够的磁盘空间
- 检查点数量 × 模型大小可能占用大量空间
- 可通过"最大保存检查点"参数限制保留数量

---

### 训练模型目录 / Training model path

| 属性 | 值 |
|------|-----|
| 类型 | 目录路径 |
| 必填 | ✅ 是 |
| 默认值 | - |

**说明**：指定用于训练的基础模型目录。

> ⚠️ **重要提醒**：此参数需要**可训练模型**，不是推理用的 GGUF 模型！

**正确的模型格式**：
- HuggingFace 格式的模型目录
- 包含 `.safetensors` 权重文件
- 包含 `config.json` 配置文件

**模型目录结构示例**：
```
model_directory/
├── config.json              # 模型配置（必需）
├── model.safetensors        # 模型权重（必需）
├── tokenizer.json           # 分词器配置
├── tokenizer_config.json    # 分词器配置
├── special_tokens_map.json  # 特殊标记映射
└── generation_config.json   # 生成配置
```

**错误示例**：
- ❌ `model.gguf` - GGUF 格式仅用于推理，不可训练
- ❌ `model.bin` - 旧版 PyTorch 格式，建议使用 safetensors

**获取可训练模型**：
1. 从 HuggingFace Hub 下载完整模型目录
2. 从下载器选择训练模型类别并下载到本地目录,注意此模型不会自动导入到模型库中

---

### (可选)分词器路径 / (opt.) Tokenizer path

| 属性 | 值 |
|------|-----|
| 类型 | 目录路径 |
| 必填 | ❌ 否 |
| 默认值 | - |
| 折叠组 | 可选参数 |

**说明**：指定自定义分词器目录路径。

**使用场景**：
- 使用与模型不同的分词器
- 使用自定义扩展的分词器
- 模型目录中缺少分词器文件

**留空处理**：自动使用模型目录中的分词器。

---

### (可选)恢复训练检查点路径 / (opt.) Checkpoint path for resume

| 属性 | 值 |
|------|-----|
| 类型 | 目录路径 |
| 必填 | ❌ 否 |
| 默认值 | - |
| 折叠组 | 可选参数 |

**说明**：从指定的检查点继续训练。

**断点续训流程**：

1. **查找检查点**：在输出目录中找到要恢复的检查点目录，如 `checkpoint-500`

2. **填写路径**：将完整检查点路径填入此参数
   ```
   /path/to/output_dir/checkpoint-500
   ```

3. **启动训练**：点击"开始训练"，训练将从该检查点继续

**注意事项**：
- 检查点目录需包含完整的训练状态文件
- 恢复后会继续之前的训练步数计数
- 如需从头开始，请清空此参数

**检查点目录结构**：
```
checkpoint-500/
├── adapter_config.json      # LoRA 配置
├── adapter_model.safetensors # LoRA 权重
├── optimizer.pt             # 优化器状态
├── scheduler.pt             # 调度器状态
├── trainer_state.json       # 训练状态
└── training_args.bin        # 训练参数
```

---

### (不建议)附加LoRA权重 / (Not recommended) Attach LoRA weights

| 属性 | 值 |
|------|-----|
| 类型 | 布尔值 |
| 必填 | ❌ 否 |
| 默认值 | false |
| 折叠组 | 可选参数 |

**说明**：在训练前加载已有的 LoRA 权重。

> ⚠️ **不建议使用**：此功能用于特殊场景，可能导致训练不稳定。

**使用场景**：
- 在现有 LoRA 基础上继续微调
- 多阶段训练流程

---

### 最大样本数 / Maximum samples

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ❌ 否 |
| 默认值 | 0 |
| 范围 | 0 - 100000 |
| 折叠组 | 优化参数 |

**说明**：限制使用的训练样本数量。

**使用场景**：
- 快速测试训练流程（设为小值如 100）
- 限制大数据集的训练量
- 调试参数配置

**特殊值**：
- `0` = 不限制，使用全部数据

---

### 评估集采样比例 / Evaluation sampling ratio

| 属性 | 值 |
|------|-----|
| 类型 | 小数 |
| 必填 | ❌ 否 |
| 默认值 | 0 |
| 范围 | 0 - 1 |
| 步长 | 0.01 |
| 折叠组 | 优化参数 |

**说明**：从训练数据中自动划分评估集的比例。

**工作流程**：
1. 加载训练数据
2. 按指定比例随机划分出评估集
3. 剩余数据用于训练

**示例**：
- `0.1` = 10% 数据用于评估，90% 用于训练
- `0` = 不划分，需要单独提供评估文件

**使用建议**：
- 如果已有独立评估文件，设为 `0`
- 如果数据量较小（< 1000 条），建议 `0.1` ~ `0.2`
- 如果数据量较大（> 10000 条），建议 `0.05` ~ `0.1`

---

### 是否重新打乱数据 / Reshuffle data

| 属性 | 值 |
|------|-----|
| 类型 | 布尔值 |
| 必填 | ❌ 否 |
| 默认值 | false |
| 折叠组 | 可选参数 |

**说明**：每个训练轮次开始时是否重新打乱数据顺序。

**建议**：
- 对于较小数据集，建议开启以增加随机性
- 对于非常大的数据集，可关闭以节省时间

---

### 数据加载器线程数 / Data loader threads

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ❌ 否 |
| 默认值 | 1 |
| 范围 | 0 - 16 |
| 折叠组 | 优化参数 |

**说明**：数据加载的并行线程数。

**调优建议**：
- CPU 核心数较多时可适当增加
- Windows 系统建议保持 0 或 1
- 过大可能导致内存占用增加

---

### 是否使用锁页内存 / Use locked page memory

| 属性 | 值 |
|------|-----|
| 类型 | 布尔值 |
| 必填 | ❌ 否 |
| 默认值 | false |
| 折叠组 | 优化参数 |

**说明**：使用锁页内存加速 CPU 到 GPU 的数据传输。

**建议**：
- GPU 训练时建议开启
- 系统内存充足时效果更好

---

## 训练配置参数

### 批次大小 / Batch size

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ✅ 是 |
| 默认值 | 2 |
| 范围 | 1 - 128 |

**说明**：每个训练步骤处理的样本数量。

**影响因素**：
- **显存占用**：批次越大，显存需求越高
- **训练稳定性**：较大批次通常更稳定
- **训练速度**：较大批次可能加快单步训练

**调优建议**：

| 显存 | 建议批次大小（LoRA） |
|------|----------------------|
| 4GB | 1 - 2 |
| 8GB | 2 - 4 |
| 16GB | 4 - 8 |
| 24GB+ | 8 - 16 |

**显存不足时**：减小批次大小，增加梯度累积步数。

---

### 梯度累积步数 / Gradient accumulation steps

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ✅ 是 |
| 默认值 | 4 |
| 范围 | 1 - 256 |

**说明**：累积多少个小批次的梯度后再更新模型参数。

**有效批次大小** = 批次大小 × 梯度累积步数

**示例**：
- 批次大小 = 2，梯度累积 = 4 → 有效批次 = 8
- 批次大小 = 1，梯度累积 = 8 → 有效批次 = 8

**使用场景**：
- 显存有限但需要大批次效果时
- 用较小显存模拟大批次训练

---

### 最大序列长度 / Max sequence length

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ✅ 是 |
| 默认值 | 512 |
| 范围 | 128 - 8192 |
| 步长 | 8 |

**说明**：输入序列的最大 token 数量。

**影响**：
- 超过此长度的序列会被截断
- 较长序列需要更多显存
- 影响模型能处理的上下文长度

**调优建议**：
- 根据训练数据的实际长度设置
- 对话数据通常 512 - 1024 足够
- 长文本任务可能需要 2048+

⚠️ 注意: 需与数据集中的最大长度相匹配(受设置中的**最大输出长度**参数的影响)，避免过多截断。
---

### 学习率 / Learning rate

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 必填 | ✅ 是 |
| 默认值 | 2e-4 |
| 范围 | 1e-6 - 1e-1 |

**说明**：模型参数更新的步长。

**调优建议**：

| 训练类型 | 建议学习率 |
|----------|------------|
| LoRA 微调 | 1e-4 ~ 5e-4 |
| 全量微调 | 1e-5 ~ 5e-5 |
| 预训练 | 1e-4 ~ 1e-3 |

**常见问题**：
- 学习率过高：训练不稳定，loss 震荡或发散
- 学习率过低：收敛缓慢，训练效果差

---

### 优化器 / Optimizer

| 属性 | 值 |
|------|-----|
| 类型 | 选择框 |
| 必填 | ✅ 是 |
| 默认值 | adamw_torch |

**说明**：选择优化算法。

**常用优化器**：

| 优化器 | 说明 |
|--------|------|
| `adamw_torch` | PyTorch 原生 AdamW，推荐使用 |
| `adamw_8bit` | 8-bit AdamW，节省显存 |
| `paged_adamw_8bit` | 分页 8-bit AdamW，显存优化 |
| `adafactor` | 内存效率高，适合大模型 |
| `sgd` | 随机梯度下降，简单稳定 |

**显存不足时**：尝试 `adamw_8bit` 或 `paged_adamw_8bit`。

---

### 学习率调度器 / LR scheduler type

| 属性 | 值 |
|------|-----|
| 类型 | 选择框 |
| 必填 | ✅ 是 |
| 默认值 | cosine |

**说明**：学习率随训练进程的变化策略。

**常用调度器**：

| 调度器 | 说明 |
|--------|------|
| `cosine` | 余弦退火，平滑下降，推荐 |
| `linear` | 线性下降 |
| `constant` | 恒定学习率 |
| `constant_with_warmup` | 预热后恒定 |
| `cosine_with_restarts` | 带重启的余弦退火 |

---

### 训练轮数 / Training epochs

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ✅ 是 |
| 默认值 | 2 |
| 范围 | 1 - 100 |

**说明**：完整遍历训练数据集的次数。

**调优建议**：
- 小数据集（< 1000 条）：3 - 10 轮
- 中等数据集（1000 - 10000 条）：2 - 5 轮
- 大数据集（> 10000 条）：1 - 3 轮

**过拟合迹象**：
- 训练 loss 持续下降但验证 loss 上升
- 此时应减少轮数或启用早停

---

### 权重衰减 / Weight decay

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 必填 | ❌ 否 |
| 默认值 | 0.01 |
| 范围 | 0 - 1 |
| 折叠组 | 高级参数 |

**说明**：L2 正则化参数，防止过拟合。

**建议**：通常保持默认值 0.01。

---

### 预热比例 / Warmup ratio

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 必填 | ❌ 否 |
| 默认值 | 0.1 |
| 范围 | 0 - 1 |
| 折叠组 | 可选参数 |

**说明**：学习率预热阶段占总训练步数的比例。

**预热过程**：
- 训练开始时，学习率从 0 逐渐增加到设定值
- 预热阶段占比由此参数控制

**建议**：0.05 - 0.1 通常效果较好。

---

### 预热步数 / Warmup steps

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ❌ 否 |
| 默认值 | 0 |
| 范围 | 0 - 10000 |
| 折叠组 | 可选参数 |

**说明**：学习率预热的具体步数。

**优先级**：如果设置了 `warmup_steps > 0`，则优先使用此值，忽略 `warmup_ratio`。

---

### 最大梯度范数 / Max gradient norm

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 必填 | ❌ 否 |
| 默认值 | 1.0 |
| 范围 | 0.1 - 10 |
| 折叠组 | 高级参数 |

**说明**：梯度裁剪阈值，防止梯度爆炸。

**建议**：通常保持默认值 1.0。

---

### 最大训练步数(-1为不限制) / Max training steps (-1=unlimited)

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ❌ 否 |
| 默认值 | -1 |
| 范围 | -1 - 100000 |
| 折叠组 | 可选参数 |

**说明**：限制最大训练步数。

**优先级**：如果设置了 `max_steps > 0`，则优先于 `num_train_epochs`。

**使用场景**：
- 精确控制训练时长
- 快速测试（设为小值如 100）

---

### 学习率余弦退火周期 / LR cosine annealing cycles

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ❌ 否 |
| 默认值 | 2 |
| 范围 | 1 - 10 |
| 折叠组 | 高级参数 |

**说明**：使用 `cosine_with_restarts` 调度器时的重启周期数。

---

### 保存策略 / Save strategy

| 属性 | 值 |
|------|-----|
| 类型 | 选择框 |
| 必填 | ❌ 否 |
| 默认值 | steps |
| 选项 | steps / epoch / no |
| 折叠组 | 保存参数 |

**说明**：检查点保存的触发策略。

| 策略 | 说明 |
|------|------|
| `steps` | 每隔指定步数保存 |
| `epoch` | 每个训练轮次结束保存 |
| `no` | 不保存中间检查点 |

> ⚠️ **配额消耗**：每保存一个检查点消耗 1 个训练配额。

---

### 保存步数 / Save steps

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ❌ 否 |
| 默认值 | 100 |
| 范围 | 1 - 10000 |
| 折叠组 | 保存参数 |

**说明**：当保存策略为 `steps` 时，每隔多少步保存一次检查点。

**配额预估**：总步数 ÷ 保存步数 = 预计检查点数 = 消耗配额数

---

### 评估策略 / Evaluation strategy

| 属性 | 值 |
|------|-----|
| 类型 | 选择框 |
| 必填 | ❌ 否 |
| 默认值 | no |
| 选项 | steps / epoch / no |
| 折叠组 | 评估参数 |

**说明**：训练过程中评估模型的策略。

**前提条件**：需要提供评估数据（评估文件或评估集采样比例）。

| 策略 | 说明 |
|------|------|
| `steps` | 每隔指定步数评估 |
| `epoch` | 每个轮次结束评估 |
| `no` | 不进行训练中评估 |

---

### 评估步数 / Evaluation steps

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ❌ 否 |
| 默认值 | 100 |
| 范围 | 1 - 10000 |
| 折叠组 | 评估参数 |

**说明**：当评估策略为 `steps` 时，每隔多少步进行一次评估。

---

### 最大保存检查点 / Max saved checkpoints

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ❌ 否 |
| 默认值 | 100 |
| 范围 | 1 - 1000 |
| 折叠组 | 保存参数 |

**说明**：保留的最大检查点数量，超出后自动删除最旧的检查点。

**建议**：根据磁盘空间设置合理值，避免空间耗尽。

---

### 保存间隔分钟 / Save interval (minutes)

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ❌ 否 |
| 默认值 | 30 |
| 范围 | 1 - 1440 |
| 折叠组 | 保存参数 |

**说明**：按时间间隔保存检查点的分钟数。

---

### 早停步数 / Early stopping patience

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ❌ 否 |
| 默认值 | 0 |
| 范围 | 0 - 100 |
| 折叠组 | 可选参数 |

**说明**：如果评估指标连续多少次评估没有改善，则提前停止训练。

**前提条件**：
- 需要启用评估策略（`eval_strategy` 不为 `no`）
- 需要提供评估数据

**特殊值**：
- `0` = 禁用早停

---

### 早停阈值 / Early stopping threshold

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 必填 | ❌ 否 |
| 默认值 | 0.005 |
| 范围 | 0.001 - 1 |
| 折叠组 | 可选参数 |

**说明**：评估指标改善的最小阈值，小于此值视为无改善。

---

## LoRA 配置参数

> 📝 **注意**：LoRA 配置仅在 SFT 训练类型下可见，预训练模式下隐藏。

### 使用LoRA微调 / Use LoRA fine-tuning

| 属性 | 值 |
|------|-----|
| 类型 | 布尔值 |
| 必填 | ✅ 是 |
| 默认值 | true |

**说明**：是否启用 LoRA（Low-Rank Adaptation）高效微调。

**LoRA 优势**：
- 大幅减少可训练参数量
- 显著降低显存需求
- 训练速度更快
- 便于保存和分发

**建议**：SFT 训练强烈推荐开启。

---

### LoRA的r参数 / LoRA r parameter

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ✅ 是 |
| 默认值 | 16 |
| 范围 | 1 - 512 |

**说明**：LoRA 的秩（rank），决定低秩矩阵的维度。

**影响**：
- r 越大，可学习参数越多，表达能力越强
- r 越大，显存和计算开销越大

**调优建议**：

| r 值 | 适用场景 |
|------|----------|
| 4 - 8 | 简单任务，显存受限 |
| 16 | 通用任务，推荐起点 |
| 32 - 64 | 复杂任务，充足显存 |
| 128+ | 特殊需求 |

---

### LoRA的alpha参数 / LoRA alpha parameter

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ✅ 是 |
| 默认值 | 16 |
| 范围 | 1 - 512 |

**说明**：LoRA 的缩放因子。

**缩放公式**：实际缩放 = alpha / r

**常见配置**：
- `alpha = r`：缩放因子为 1（推荐）
- `alpha = 2r`：缩放因子为 2，增强 LoRA 影响

---

### LoRA的dropout / LoRA dropout

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 必填 | ❌ 否 |
| 默认值 | 0.0 |
| 范围 | 0 - 1 |
| 折叠组 | 高级参数 |

**说明**：LoRA 层的 Dropout 比例，用于正则化。

**建议**：
- 数据量较大时可保持 0
- 数据量较小或易过拟合时设为 0.05 - 0.1

---

### LoRA目标模块 / LoRA target modules

| 属性 | 值 |
|------|-----|
| 类型 | 多选框 |
| 必填 | ❌ 否 |
| 默认值 | ["q_proj", "k_proj", "v_proj","o_proj","gate_proj","up_proj","down_proj"] |
| 折叠组 | 高级参数 |

**说明**：选择应用 LoRA 的模型模块。

**可选模块**：

| 模块 | 说明 |
|------|------|
| `q_proj` | Query 投影层|
| `k_proj` | Key 投影层 |
| `v_proj` | Value 投影层|
| `o_proj` | Output 投影层 |
| `gate_proj` | 门控投影层 |
| `up_proj` | 上投影层 |
| `down_proj` | 下投影层 |
| `embed_tokens` | 嵌入层 |
| `lm_head` | 语言模型头 |

**调优建议**：
- 基础配置：`q_proj`, `k_proj`, `v_proj`, `o_proj`
- 完整配置：再添加 `gate_proj`, `up_proj`, `down_proj`

---

### 训练后合并LoRA权重 / Merge LoRA weights after training

| 属性 | 值 |
|------|-----|
| 类型 | 布尔值 |
| 必填 | ❌ 否 |
| 默认值 | false |
| 折叠组 | 可选参数 |

**说明**：训练完成后是否自动将 LoRA 权重合并到基础模型。

**合并后**：
- 生成完整的模型权重文件
- 不再需要加载 LoRA 适配器
- 文件体积与原始模型相同

**不合并**：
- 仅保存 LoRA 适配器权重（体积小）
- 推理时需要同时加载基础模型和 LoRA

---

### PEFT配置路径 / PEFT config path

| 属性 | 值 |
|------|-----|
| 类型 | 文件路径 |
| 必填 | ❌ 否 |
| 默认值 | - |
| 折叠组 | 可选参数 |

**说明**：指定自定义的 PEFT 配置文件路径。

**使用场景**：使用预定义的 PEFT 配置而非界面参数。

---

## 优化配置参数

### 使用 QLoRA / Use QLoRA

| 属性 | 值 |
|------|-----|
| 类型 | 布尔值 |
| 必填 | ❌ 否 |
| 默认值 | false |

**说明**：启用 4-bit QLoRA 量化微调技术.量化过程是在加载模型到 GPU 动态完成.基础模型权重可以是原始精度

**要求**：
- NVIDIA Ampere 及以上架构 GPU（RTX 30 系列、A100 等）
- 依赖通过环境安装的 bitsandbytes 库支持, 可能存在兼容性问题
- 适用于显存受限场景

**优势**：
- 显著减少显存占用约50% - 75%
- 允许在较小显存 GPU 上训练大模型

---

### 使用8-bit优化器 / Use 8-bit optimizers

| 属性 | 值 |
|------|-----|
| 类型 | 布尔值 |
| 必填 | ❌ 否 |
| 默认值 | false |

**说明**：使用 8-bit 版本的优化器（如 8-bit AdamW）以减少显存占用。

**要求**：
- NVIDIA Ampere 及以上架构 GPU（RTX 30 系列、A100 等）
- 依赖通过环境安装的 bitsandbytes 库支持, 可能存在兼容性问题

**优势**：
- 减少优化器状态的显存占用约 75%
- 适合显存受限的训练场景

---

### 使用FP16混合精度 / Use FP16 mixed precision

| 属性 | 值 |
|------|-----|
| 类型 | 布尔值 |
| 必填 | ✅ 是 |
| 默认值 | true |

**说明**：使用 FP16 半精度浮点数进行混合精度训练。

**优势**：
- 减少显存占用约 50%
- 加速训练过程
- 保持训练精度

**建议**：GPU 训练时推荐开启。

---

### 使用BF16混合精度(NVIDIA GPU) / Use BF16 mixed precision (NVIDIA GPU)

| 属性 | 值 |
|------|-----|
| 类型 | 布尔值 |
| 必填 | ❌ 否 |
| 默认值 | false |

**说明**：使用 BF16 格式进行混合精度训练。

**要求**：
- NVIDIA Ampere 及以上架构 GPU（RTX 30 系列、A100 等）
- 与 FP16 二选一

**优势**：
- 数值范围更大，训练更稳定
- 适合大模型训练

---

### 使用TF32(NVIDIA GPU) / Use TF32 (NVIDIA GPU)

| 属性 | 值 |
|------|-----|
| 类型 | 布尔值 |
| 必填 | ❌ 否 |
| 默认值 | false |

**说明**：使用 TensorFloat-32 格式加速矩阵运算。

**要求**：NVIDIA Ampere 及以上架构 GPU。

---

### 梯度检查点 / Gradient checkpointing

| 属性 | 值 |
|------|-----|
| 类型 | 布尔值 |
| 必填 | ✅ 是 |
| 默认值 | true |

**说明**：以计算时间换取显存空间。

**工作原理**：
- 训练时不保存中间激活值
- 反向传播时重新计算
- 显著减少显存占用

**建议**：显存受限时强烈推荐开启。

---

## 日志配置参数

### 日志级别 / Log level

| 属性 | 值 |
|------|-----|
| 类型 | 选择框 |
| 必填 | ✅ 是 |
| 默认值 | info |
| 选项 | debug / info / warning / error |

**说明**：训练日志的详细程度。

| 级别 | 说明 |
|------|------|
| `debug` | 最详细，包含调试信息 |
| `info` | 常规信息，推荐 |
| `warning` | 仅警告和错误 |
| `error` | 仅错误信息 |

---

### 日志记录步数 / Logging steps

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ✅ 是 |
| 默认值 | 10 |
| 范围 | 1 - 1000 |

**说明**：每隔多少步记录一次训练日志。

**影响**：
- 值越小，监控界面更新越频繁
- 值过小可能影响训练效率

---

## 通用配置参数

### 随机种子 / Random seed

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 必填 | ✅ 是 |
| 默认值 | 42 |
| 范围 | 0 - 999999 |

**说明**：控制训练过程中的随机性。

**作用**：
- 相同种子可复现训练结果
- 便于对比实验

---

## 参数模板

### 系统预设模板

系统提供两个默认模板：

| 模板 | 说明 |
|------|------|
| SFT | 监督微调默认配置，启用 LoRA |
| Pretrain | 预训练默认配置，不使用 LoRA |

### 自定义模板

1. **保存模板**：配置好参数后，点击"另存为"保存为自定义模板
2. **加载模板**：从模板下拉框选择已保存的模板
3. **删除模板**：在下拉框中点击模板右侧的删除图标

### 临时参数

当创建任务时勾选“临时模板”选项：

- **不覆盖原模板**：当前修改的参数不会保存到当前选中的模板中
- **仅保存为任务参数**：参数将作为该任务的独立配置
- **后端读取任务参数**：训练时后端仅使用当前的临时参数与模板无关
- **支持后续另存**：如果发现这套临时参数效果较好，可以稍后将其另存为一个新模板

---

## 训练流程

### 创建新任务

1. 在任务管理中选择"新建任务"
2. 设置任务名称（或使用自动生成的名称）
3. 选择训练类型（SFT 或预训练）
4. 选择配置模板或使用自定义配置
5. 点击"配置参数"调整各项参数
6. 确认必填参数已填写完整
7. 点击"开始训练"

### 继续已有任务

1. 在任务管理中选择已有任务
2. 系统自动加载该任务的参数配置
3. 可根据需要调整参数
4. 点击"开始训练"

### 断点续训

1. 在"恢复训练检查点路径"中填写检查点目录路径
2. 确保检查点包含完整的训练状态
3. 点击"开始训练"，将从该检查点继续

### 环境检查

启动训练前，系统会自动检查：
- Python 训练环境是否就绪
- 必要的依赖包是否安装
- GPU/CUDA 是否可用（如果选择 GPU 训练）

---

## 后续文档

- [概述](./overview.md) - 训练功能总览
- [监控模块详解](./monitor.md) - 实时监控和历史回顾
- [评估模块详解](./evaluate.md) - 检查点评估和对比
- [测试模块详解](./test.md) - 交互式测试
- [打包模块详解](./package.md) - GGUF 导出
