# 训练测试模块详解

> v1.0.0
> 2025-12

> 📌 **模块定位**：交互式测试检查点的实际推理效果，验证模型在真实对话场景中的回答质量。

## 目录
- [概述](#概述)
- [使用场景](#使用场景)
- [推理参数](#推理参数)
  - [基础参数](#基础参数)
  - [高级参数](#高级参数)
- [测试流程](#测试流程)
- [测试建议](#测试建议)
- [常见问题](#常见问题)
- [与其他模块的关系](#与其他模块的关系)
- [下一步](#下一步)

---

## 概述

测试模块提供交互式对话界面，让用户可以手动输入问题并查看模型的实际回复，直观验证训练效果。

### 核心功能

| 功能 | 说明 |
|------|------|
| 检查点选择 | 选择要测试的训练检查点 |
| 交互对话 | 输入问题获取模型回复 |
| 参数调整 | 调整推理参数观察效果变化 |
| 多轮对话 | 支持连续多轮对话测试 |

---

## 使用场景

### 典型工作流

1. **评估后验证**：评估模块筛选出高分检查点后，用测试模块实际体验
2. **对比测试**：切换不同检查点，对同一问题对比回答质量
3. **边界测试**：测试模型在极端或边缘情况下的表现
4. **参数调优**：调整推理参数，找到最佳生成效果

### 与评估模块配合

```
评估模块 → 找出高分检查点 → 测试模块验证 → 确定最终检查点
```

---

## 推理参数

### 基础参数

#### 温度 / Temperature

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 默认值 | 0.7 |
| 范围 | 0 - 2 |

**说明**：控制输出的随机性和创造性。

| 温度值 | 效果 |
|--------|------|
| 0 - 0.3 | 保守、确定性高、适合事实问答 |
| 0.4 - 0.7 | 平衡、适合日常对话 |
| 0.8 - 1.2 | 创造性高、适合创意写作 |
| > 1.2 | 高度随机、可能不连贯 |

---

#### 最大长度 / Max length

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 默认值 | 256 |
| 范围 | 1 - 8192 |

**说明**：模型生成的最大 token 数量。

**设置建议**：
- 简短回答：128 - 256
- 详细解释：512 - 1024
- 长文生成：2048+

---

#### Top P（核采样）

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 默认值 | 0.9 |
| 范围 | 0 - 1 |

**说明**：从累积概率达到 P 的候选词中采样。

| Top P 值 | 效果 |
|----------|------|
| 0.1 - 0.5 | 保守，只选高概率词 |
| 0.7 - 0.9 | 平衡，推荐值 |
| 0.95 - 1.0 | 宽松，更多样化 |

---

#### Top K

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 默认值 | 50 |
| 范围 | 0 - 100 |

**说明**：只从概率最高的 K 个词中采样。

**使用建议**：
- 设为 0 表示不使用 Top K 限制
- 通常 20-50 是较好的选择
- 与 Top P 配合使用效果更好

---

#### 重复惩罚 / Repeat penalty

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 默认值 | 1.1 |
| 范围 | 0 - 2 |

**说明**：抑制模型重复已生成的内容。

| 值 | 效果 |
|----|------|
| 1.0 | 无惩罚 |
| 1.1 - 1.2 | 轻微抑制，推荐 |
| 1.3 - 1.5 | 明显抑制 |
| > 1.5 | 强烈抑制，可能影响流畅性 |

---

#### 存在惩罚 / Presence penalty

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 默认值 | 1.1 |
| 范围 | 0 - 2 |

**说明**：惩罚已出现过的 token，鼓励模型使用新词汇。

**与重复惩罚的区别**：
- 重复惩罚：惩罚连续重复
- 存在惩罚：惩罚任何已出现的词

---

#### Min P

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 默认值 | 0.0 |
| 范围 | 0 - 1 |

**说明**：过滤掉概率低于阈值的词。

**使用场景**：
- 设为 0 表示不使用
- 设为 0.05-0.1 可过滤低概率噪声

---

#### 随机种子 / Random seed

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 默认值 | 42 |
| 范围 | 0 - 999999 |

**说明**：固定随机种子可复现相同的输出。

**使用场景**：
- 对比测试时使用相同种子确保公平
- 调试时固定种子便于复现问题

---

### 高级参数

#### 启用思考模式 / Enable thinking

| 属性 | 值 |
|------|-----|
| 类型 | 布尔值 |
| 默认值 | false |

**说明**：启用模型的"思考"能力（如果模型支持）。

**适用模型**：带有思考标签训练的模型，如 QwQ 系列。

---

#### 系统提示词 / System prompt

| 属性 | 值 |
|------|-----|
| 类型 | 文本 |
| 默认值 | 空 |
| 最大长度 | 1000 字符 |

**说明**：设置模型的角色和行为指导。

**示例**：
```
你是一个专业的客服助手，请用友好、专业的语气回答用户问题。
```

---

## 测试流程

### 1. 选择检查点

从任务的检查点列表中选择要测试的检查点：
- 可以基于评估模块的推荐选择
- 可以选择不同训练步数的检查点对比

### 2. 配置参数

点击参数配置按钮：
- 调整推理参数
- 设置系统提示词（可选）
- 配置思考模式（可选）

### 3. 开始对话

在对话框中：
1. 输入测试问题
2. 等待模型生成回复
3. 查看回复内容
4. 继续输入下一个问题（多轮对话）

### 4. 分析结果

关注以下方面：
- **回答准确性**：是否正确回答问题
- **回答流畅性**：语言是否自然通顺
- **格式规范性**：是否符合预期的输出格式
- **知识正确性**：是否包含正确的知识

---

## 测试建议

### 测试用例设计

| 类型 | 说明 | 示例 |
|------|------|------|
| 正常场景 | 训练数据覆盖的典型问题 | 标准问答对 |
| 边界场景 | 训练数据边缘的问题 | 罕见词汇、复杂语法 |
| 异常场景 | 训练数据之外的问题 | 测试模型的拒绝能力 |
| 对比场景 | 与基础模型对比 | 验证微调效果 |

### 参数调优策略

1. **从默认开始**
   - 使用默认参数获得基准效果

2. **逐个调整**
   - 每次只调整一个参数
   - 观察效果变化

3. **记录最佳组合**
   - 找到效果最好的参数组合
   - 用于后续的打包配置

### 多检查点对比

1. 准备一组标准测试问题
2. 使用相同的参数和随机种子
3. 依次测试不同检查点
4. 记录并对比回答质量

---

## 常见问题

### 回答不完整

**可能原因**：
- 最大长度设置过小
- 模型生成了 EOS 标记

**解决方法**：
- 增大最大长度参数
- 检查训练数据中的结束标记格式

### 回答重复

**可能原因**：
- 重复惩罚过低
- 温度过高导致采样不稳定

**解决方法**：
- 增大重复惩罚（如 1.2-1.3）
- 适当降低温度

### 回答偏离主题

**可能原因**：
- 训练数据质量问题
- 推理参数不当

**解决方法**：
- 降低温度获得更确定的回答
- 检查训练数据的相关性

### 加载检查点失败

**可能原因**：
- 检查点文件不完整
- 内存不足

**解决方法**：
- 确认检查点目录包含必要文件
- 关闭其他占用内存的程序

---

## 与其他模块的关系

```
准备模块 → 监控模块 → 评估模块 → 测试模块 → 打包模块
   │          │          │          │          │
 创建任务    监控进度    量化评估   实际验证   导出模型
```

**测试模块的定位**：
- 在评估模块之后：基于评估分数选择检查点
- 在打包模块之前：确认检查点质量后再打包

---

## 后续文档

- [概述](./overview.md) - 训练功能总览
- [准备模块详解](./prepare.md) - 任务创建和参数配置
- [监控模块详解](./monitor.md) - 训练监控
- [评估模块详解](./evaluate.md) - 检查点评估
- [打包模块详解](./package.md) - GGUF 导出
