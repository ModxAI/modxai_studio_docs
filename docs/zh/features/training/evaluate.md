# 训练评估模块详解

> v1.0.0
> 2025-12

> 📌 **模块定位**：自动化评估检查点质量，通过标准化样本测试帮助用户找到最佳检查点。

## 目录
- [概述](#概述)
- [评估样本](#评估样本)
- [评估参数](#评估参数)
- [评估流程](#评估流程)
- [评估指标](#评估指标)
- [使用建议](#使用建议)
- [与测试模块的区别](#与测试模块的区别)

---

## 概述

评估模块使用预定义的问答样本对训练检查点进行批量测试，自动计算相似度分数，帮助用户客观评估模型训练效果。

### 核心功能

| 功能 | 说明 |
|------|------|
| 批量评估 | 使用样本数据集自动评估检查点 |
| 分数计算 | 计算模型输出与标准答案的相似度 |
| 结果对比 | 多个检查点的评估结果可视化对比 |
| 最佳推荐 | 自动推荐评分最高的检查点 |

---

## 评估样本

### 默认样本文件

系统随包发布默认评估样本文件：

```
server/resources/example/train_evaluation/model_evaluation_samples.json
```

首次运行评估功能时，此文件会被复制到用户数据目录作为默认配置。

### 样本格式

```json
{
  "train": [
    {
      "prompt": "问题文本",
      "completion": "标准答案"
    }
  ],
  "validation": [
    {
      "prompt": "验证问题",
      "completion": "验证答案"
    }
  ]
}
```

### 样本分组说明

| 分组 | 用途 |
|------|------|
| `train` | 训练集样本，用于评估模型对训练数据的学习效果 |
| `validation` | 验证集样本，用于评估模型的泛化能力 |

### 自定义样本

用户可以修改样本文件以适应自己的评估需求：

1. **添加样本**：在对应分组的数组中添加新的 `prompt`/`completion` 对象
2. **修改样本**：编辑现有样本的问题和答案
3. **删除样本**：移除不需要的样本对象

**样本编写建议**：

| 类型 | 建议 |
|------|------|
| 问题覆盖 | 覆盖训练数据的主要场景 |
| 答案标准 | 使用期望的标准回答格式 |
| 数量平衡 | train 和 validation 数量适当均衡 |
| 难度梯度 | 包含简单到复杂的不同难度问题 |

---

## 评估参数

### 采样控制参数

#### 采样比例 / Sample ratio

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 默认值 | 0.3 |
| 范围 | 0.1 - 1.0 |

**说明**：从样本集中随机抽取的比例。

**使用场景**：
- 样本较多时，设置较低比例加快评估速度
- 需要全面评估时，设置为 1.0 使用全部样本

---

#### 最大样本数 / Max samples

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 默认值 | 20 |
| 范围 | 5 - 100 |

**说明**：单次评估使用的最大样本数量。

**作用**：限制评估时间，避免样本过多导致评估时间过长。

---

#### 最小样本数 / Min samples

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 默认值 | 5 |
| 范围 | 1 - 50 |

**说明**：确保评估使用的最少样本数量。

**作用**：即使采样比例计算结果较少，也保证最低样本数量。

---

### 推理参数

评估时的模型推理参数，与常规推理参数相同：

#### 温度 / Temperature

| 属性 | 值 |
|------|-----|
| 类型 | 浮点数 |
| 默认值 | 0.3 |
| 范围 | 0 - 1 |

**说明**：控制输出的随机性。

**评估建议**：使用较低温度（0.1-0.3）以获得更稳定、可复现的评估结果。

---

#### 最大长度 / Max length

| 属性 | 值 |
|------|-----|
| 类型 | 整数 |
| 默认值 | 256 |
| 范围 | 32 - 2048 |

**说明**：模型生成的最大 token 数量。

**评估建议**：根据样本答案的平均长度设置，通常 256-512 足够。

---

### 高级参数

以下参数位于折叠面板中：

| 参数 | 默认值 | 说明 |
|------|--------|------|
| Top K | 20 | 采样时保留概率最高的 K 个词 |
| Top P | 0.9 | 核采样的累积概率阈值 |
| 重复惩罚 | 1.1 | 抑制重复内容的惩罚系数 |
| 存在惩罚 | 1.1 | 抑制已出现 token 的惩罚系数 |
| Min P | 0.0 | 最小概率阈值 |
| 随机种子 | 42 | 固定种子可复现评估结果 |

---

## 评估流程

### 1. 选择检查点

在评估页面选择要评估的检查点：
- 可以选择单个检查点进行评估
- 可以选择多个检查点进行对比评估

### 2. 配置参数

点击参数配置按钮，调整评估参数：
- 设置采样比例和样本数限制
- 调整推理参数（推荐使用低温度）
- 确认评估样本文件路径

### 3. 执行评估

1. 点击"开始评估"按钮
2. 系统加载检查点并初始化模型
3. 逐个样本进行推理
4. 计算模型输出与标准答案的相似度
5. 生成评估报告

### 4. 查看结果

评估完成后显示：
- **总体分数**：所有样本的平均相似度分数
- **详细结果**：每个样本的问题、标准答案、模型输出和分数
- **对比图表**：多检查点评估时的分数对比

---

## 评估指标

### 相似度计算

评估使用文本相似度算法计算模型输出与标准答案的匹配程度：

| 因素 | 权重 |
|------|------|
| 语义相似度 | 主要指标 |
| 关键词覆盖 | 辅助指标 |
| 格式匹配 | 参考指标 |

### 分数解读

| 分数范围 | 说明 |
|----------|------|
| 0.8 - 1.0 | 优秀，模型输出与标准答案高度一致 |
| 0.6 - 0.8 | 良好，模型基本理解任务要求 |
| 0.4 - 0.6 | 一般，模型部分理解任务 |
| 0.0 - 0.4 | 较差，模型输出偏离预期 |

---

## 使用建议

### 评估策略

1. **定期评估**
   - 每隔一定训练时步数（如 100-500 步）评估一次
   - 追踪模型质量随训练进度的变化

2. **对比评估**
   - 选择多个检查点同时评估
   - 找出最佳训练节点

3. **全面评估**
   - 最终选择检查点时使用全部样本（采样比例 1.0）
   - 获得更可靠的评估结果

### 样本设计

1. **代表性**
   - 样本应覆盖训练数据的主要场景
   - 包含不同类型的问题

2. **标准化**
   - 答案格式统一
   - 便于客观评分

3. **更新维护**
   - 根据实际需求调整样本
   - 定期清理过时的样本

---

## 与测试模块的区别

| 维度 | 评估模块 | 测试模块 |
|------|----------|----------|
| 目的 | 量化评估检查点质量 | 交互式验证模型效果 |
| 方式 | 自动化批量测试 | 手动输入问题测试 |
| 输出 | 分数和评估报告 | 模型的实时回复 |
| 使用场景 | 筛选最佳检查点 | 确认模型实际表现 |

**推荐工作流**：
1. 先用评估模块找出分数较高的检查点
2. 再用测试模块实际验证这些检查点的回答质量
3. 最终确定用于打包的检查点

---

## 后续文档

- [概述](./overview.md) - 训练功能总览
- [准备模块详解](./prepare.md) - 任务创建和参数配置
- [监控模块详解](./monitor.md) - 训练监控
- [测试模块详解](./test.md) - 交互式测试
- [打包模块详解](./package.md) - GGUF 导出
