# RAG 知识库数据处理

> v1.0.0
> 2025-12

本文详细介绍如何使用 ModxAI Studio 的 RAG（检索增强生成）数据处理功能，将文档转换为可供 AI 对话检索使用的向量知识库。

---

## 目录

- [环境要求](#环境要求)
- [功能简介](#功能简介)
- [处理流程](#处理流程)
- [各步骤详解](#各步骤详解)
- [参数配置说明](#参数配置说明)
- [输出与存储](#输出与存储)
- [在聊天中使用](#在聊天中使用)
- [从收藏数据导出](#从收藏数据导出)
- [注意事项](#注意事项)
- [常见问题](#常见问题)

---

## 环境要求

**本功能需在设置中安装额外的CPU或GPU环境依赖。**
- 进入 ModxAI Studio 的**设置**页面
- 在**环境管理**标签页，选择并安装所需的环境（CPU/GPU）
- 安装完成后，返回数据处理页面即可使用相关功能

---

## 功能简介

RAG 知识库是一种让 AI 能够"查阅资料"来回答问题的技术。通过将您的文档转换为向量形式存储，AI 在对话时可以检索相关内容，从而给出更准确、更专业的回答。

**适用场景**：
- 企业内部知识库问答
- 产品文档智能客服
- 专业领域资料检索
- 个人知识管理助手

**支持的文件格式**：
- 文档类：PDF、Word（.doc/.docx）、PowerPoint（.ppt/.pptx）、Excel（.xls/.xlsx）
- 网页类：HTML（.html/.htm）
- 文本类：TXT、Markdown、CSV、JSON、XML
- 压缩包：ZIP（会自动解压并处理内部文件）

---

## 处理流程

RAG 数据处理包含 6 个步骤，前 4 步与 SFT 文本处理共用，后 2 步专门用于向量化：

| 步骤 | 名称 | 说明 | 可配置 |
|------|------|------|--------|
| 0 | 转换 | 解析各类文件格式，提取纯文本内容 | - |
| 1 | 清洗 | 清理无效内容，去除噪音数据 | ✓ |
| 2 | 拆分 | 将长文档切分为适合检索的文本块 | ✓ |
| 3 | 分析 | 数据质量分析，按复杂度分组 | - |
| 4 | 生成向量 | 使用向量模型将文本转换为向量 | ✓ |
| 5 | 存储向量 | 将向量数据写入向量数据库 | ✓ |

---

## 各步骤详解

### 步骤 0：转换

**作用**：读取您选择的文件，将 PDF、Word、HTML 等各种格式统一转换为纯文本。

**处理内容**：
- PDF：提取文字内容，保留段落结构
- Word/PPT/Excel：读取文档内容和表格数据
- HTML：清除标签，保留正文
- 压缩包：自动解压并递归处理内部文件

**说明**：此步骤为自动处理，无需配置参数。

---

### 步骤 1：清洗

**作用**：清理文档中的无效内容，提高数据质量。

**处理内容**：
- 去除页眉页脚、导航栏等重复性内容
- 清理特殊符号和乱码
- 过滤过短的无意义段落

#### 可配置参数

| 参数 | 说明 | 默认值 | 建议 |
|------|------|--------|------|
| **最小段落长度** | 低于此字符数的段落将被过滤 | 3 | 根据内容类型调整，技术文档可设置更大值 |
| **样本作用范围** | 清洗规则的应用范围 | 结构 | `结构` - 只清理页眉页脚等结构区域<br>`全文` - 对全文应用清洗规则 |
| **清洗样本** | 自定义需要清除的内容 | 空 | 用 `\|` 分隔多个样本，如：`版权所有\|Copyright\|联系我们`<br>建议每个样本不超过 20 个字符 |

**使用建议**：
- 如果文档来源单一（如公司内部文档），可以添加统一的页脚信息作为清洗样本
- 技术文档建议将最小段落长度设为 5-10，避免过滤掉代码注释

---

### 步骤 2：拆分

**作用**：将长文档切分为适合检索的文本块（Chunk）。这是 RAG 系统的关键步骤，直接影响检索效果。

**处理逻辑**：
- 优先按标题和段落自然边界切分
- 保持语义完整性，避免句子中间断开
- 超长段落会进一步按句子拆分

#### 可配置参数

| 参数 | 说明 | 默认值 | 建议 |
|------|------|--------|------|
| **最小段落长度** | 拆分时保留的最小段落字符数 | 3 | 过小会产生碎片化内容 |
| **最小文档长度** | 文档最少需要的 Token 数 | 10 | 过短的文档将被过滤 |
| **最小块长度** | 单个文本块的最小 Token 数 | 15 | 建议 15-50，过小影响检索质量 |

**Token 说明**：Token 是模型处理文本的基本单位，中文约 1 个字 ≈ 1-2 个 Token，英文约 1 个单词 ≈ 1-3 个 Token。

**使用建议**：
- 问答场景：最小块长度设为 30-50，确保每个块包含完整信息
- 长文档检索：可以适当增大块长度，提高上下文完整性

---

### 步骤 3：分析

**作用**：对处理后的数据进行质量分析，识别重复和异常内容，并按内容复杂度分组。

**处理内容**：
- **近重复检测**：找出高度相似的文本块，保留代表性内容
- **离群点检测**：识别与主题偏离较大的异常内容
- **复杂度分组**：将内容按高/中/低复杂度分类存储

#### 嵌入模型依赖

此步骤的近重复检测功能支持使用嵌入模型来提高检测准确度。系统默认使用 `all-MiniLM-L6-v2` 模型：

- **本地优先**：系统会优先尝试加载本地已下载的模型
- **自动降级**：如果嵌入模型不可用，会自动使用 TF-IDF 算法进行检测
- **可选配置**：您可以在模型库中下载该嵌入模型，或使用其他兼容的 Sentence Transformer 模型

**说明**：此步骤为自动处理，无需配置参数。嵌入模型为可选项，不影响基本功能。

---

### 步骤 4：生成向量

**作用**：使用向量模型（Embedding Model）将文本块转换为高维向量，这是实现语义检索的核心步骤。

**工作原理**：向量模型将文本的"含义"转换为数学向量，语义相近的内容在向量空间中距离也相近，这使得 AI 能够找到与问题相关的内容。

#### 可配置参数

| 参数 | 说明 | 默认值 | 建议 |
|------|------|--------|------|
| **向量模型** | 选择用于生成向量的模型 | 需手动选择 | 必须从模型库中选择已导入的向量模型（Embedding 类型） |
| **向量归一化** | 是否对向量进行归一化处理 | 开启 | 建议保持开启，可提高检索效果 |

**模型选择建议**：
- 中文为主：选择支持中文的模型，如 `qwen3-embedding`、`bge-large-zh`、`m3e-base`
- 英文为主：可选择 `bge-large-en`、`e5-large`
- 多语言混合：选择多语言模型，如 `bge-m3`

**向量归一化说明**：归一化后的向量长度统一为 1，便于使用余弦相似度进行检索比较。建议保持开启。

---

### 步骤 5：存储向量

**作用**：将生成的向量和对应文本存储到向量数据库中，以便后续检索使用。

#### 可配置参数

| 参数 | 说明 | 默认值 | 建议 |
|------|------|--------|------|
| **集合名称** | 向量库的标识名称 | 自动生成 | 建议使用有意义的名称，如 `产品手册_v1`、`技术文档` |
| **目标维度** | 向量的维度大小 | 1024 | 需与模型输出维度匹配，通常不需修改 |
| **向量池化策略** | 多维向量的合并方式 | mean | 高级选项，一般保持默认 |

**集合名称说明**：
- 集合名称是知识库的唯一标识，在聊天时用于选择要检索的知识库
- 建议使用简洁明了的命名，便于识别和管理
- 同名集合的新数据会追加到现有集合中

**池化策略说明**（高级选项）：
- `mean`：平均池化，综合所有特征，最常用
- `max`：最大池化，保留最显著特征
- `cls`：使用首位置的特征向量

---

## 输出与存储

### 中间文件

处理过程中的数据按步骤存储在输出目录：

```
输出目录/
├── ori/              # 步骤 0：原始解析数据
├── opt1/             # 步骤 1：清洗后数据
├── opt2/             # 步骤 2：拆分后数据
├── opt3/             # 步骤 3：分析后数据
│   ├── high_complexity/
│   ├── mid_complexity/
│   └── low_complexity/
└── opt4/             # 步骤 4：向量数据（增量目录）
```

### 向量数据库

最终的向量数据存储在**独立的向量数据库**中，而非应用的本地数据库：

- **存储位置**：输出目录下的向量存储文件夹
- **数据库类型**：Qdrant 向量数据库（本地模式）
- **数据格式**：向量 + 原始文本 + 元数据

**重要说明**：
- 向量数据库与中间处理文件分开存储
- 每个集合按向量维度自动分组，例如 `产品手册_1024d`
- 向量数据库包含完整的检索所需信息，无需保留中间文件

---

## 在聊天中使用

完成 RAG 数据处理后，可以在聊天中启用知识库检索：

1. **打开参数设置**：在聊天界面点击参数抽屉
2. **选择知识库**：在 RAG 配置区域选择已创建的集合
3. **开始对话**：AI 会自动检索相关内容辅助回答

### 管理知识库

- **查看列表**：在参数抽屉中可以看到所有可用的知识库集合
- **删除集合**：点击集合旁的删除按钮可移除知识库
- **删除注意**：删除操作仅移除集合配置，**不会删除已存储的向量数据文件**

### 目前限制

- 暂不支持重新导入已存在的向量数据库
- 如需更新知识库内容，建议使用新的集合名称或清理后重新处理

---

## 从收藏数据导出

除了直接处理文档，您还可以将聊天中积累的收藏数据导出为 RAG 格式：

### 操作步骤

1. **进入收藏数据管理**：在聊天界面点击"收藏"按钮
2. **选择导出数据**：勾选要导出的对话或点赞内容
3. **选择导出格式**：选择"RAG 知识库格式"
4. **配置导出选项**：设置名称等参数
5. **执行导出**：导出后需从(**生成向量**)节点开始完成生成向量并存入向量数据库的处理

### 使用场景

- 将高质量的 AI 回答积累为知识库
- 基于历史对话构建专属问答库
- 将点赞的优质内容转化为可检索知识

---

## 注意事项

### 环境要求

| 要求 | 说明 |
|------|------|
| **环境** | 必须在**设置**中安装环境才能运行向量模型 |
| 向量模型 | 必须在模型库中导入至少一个 Embedding 类型的模型 |
| 磁盘空间 | 向量数据库会占用一定存储空间，请确保输出目录有足够空间 |

### 配额消耗

RAG 数据处理会消耗免费配额：
- 步骤 0（转换）：免费
- 步骤 1-5：每处理/生成一条数据记录消耗 1 个配额单位

### 性能建议

- **首次处理**：大量文档首次处理可能需要较长时间，建议先用少量文件测试
- **增量更新**：支持增量处理，新增文件无需重新处理全部数据
- **GPU 加速**：如果有 GPU，向量生成速度会显著提升

---

## 常见问题

**Q：向量模型应该选择哪个？**

A：根据您的内容语言选择：
- 纯中文内容：推荐 `qwen3-embedding`、`bge-large-zh` 或 `m3e-base`
- 纯英文内容：推荐 `qwen3-embedding`、`bge-large-en` 或 `e5-large`
- 中英混合：推荐 `qwen3-embedding`、`bge-m3` 多语言模型

**Q：处理失败如何排查？**

A：常见原因：
1. 未在**设置**中安装环境 - 请在**设置**中进行配置
2. 未导入向量模型 - 请先在模型库导入 Embedding 类型模型
3. 配额不足 - 检查剩余配额或等待重置

**Q：可以修改已有知识库的内容吗？**

A：目前不支持直接编辑。如需更新，建议：
1. 删除旧集合
2. 修改源文档后重新处理
3. 或使用新的集合名称创建更新版本

**Q：删除聊天中的知识库会影响数据吗？**

A：在聊天参数抽屉中删除知识库集合，只是取消关联，**不会删除实际的向量数据文件**。如需彻底删除，需要手动清理输出目录中的向量存储文件。

**Q：步骤 3 分析时间很长，正常吗？**

A：如果数据量较大，质量分析确实需要一定时间。如果嵌入模型可用，会使用向量相似度进行近重复检测，效果更好但耗时略长。系统会自动选择最优方案。

**Q：集合名称可以使用中文吗？**

A：建议使用英文或拼音命名，中文可能在某些系统环境下导致兼容性问题。

---

## 后续文档

- [数据处理概述](./overview.md) - 了解数据处理模块的整体架构
- [SFT 数据处理](./sft.md) - 用于模型微调的数据集生成
- [音频转文本](./audio2text.md) - 音频转录功能详细指南
