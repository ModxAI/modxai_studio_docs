# RAG 知识库数据处理

> v1.0.0
> 2025-12

本文详细介绍如何使用 ModxAI Studio 的 RAG（检索增强生成）数据处理功能，将文档转换为可供 AI 对话检索使用的智能知识库。

---

## 目录

- [环境要求](#环境要求)
- [功能简介](#功能简介)
- [系统特性](#系统特性)
- [处理流程](#处理流程)
- [各步骤详解](#各步骤详解)
- [参数配置说明](#参数配置说明)
- [输出与存储](#输出与存储)
- [在聊天中使用](#在聊天中使用)
- [从收藏数据导出](#从收藏数据导出)
- [注意事项](#注意事项)
- [常见问题](#常见问题)

---

## 环境要求

**本功能需在设置中安装额外的 CPU 或 GPU 环境依赖。**
- 进入 ModxAI Studio 的**设置**页面
- 在**环境管理**标签页，选择并安装所需的环境（CPU/GPU）
- 安装完成后，返回数据处理页面即可使用相关功能

---

## 功能简介

RAG 知识库是一种让 AI 能够"查阅资料"来回答问题的技术。通过将您的文档转换为向量形式存储，AI 在对话时可以检索相关内容，从而给出更准确、更专业的回答。

与传统的全文检索不同，RAG 系统能够理解问题的**语义含义**，即使您的提问方式与文档中的表述不完全一致，也能找到相关内容。

**适用场景**：
- 企业内部知识库问答
- 产品文档智能客服
- 专业领域资料检索
- 个人知识管理助手
- 技术文档快速查询

**支持的文件格式**：
- 文档类：PDF、Word（.doc/.docx）、PowerPoint（.ppt/.pptx）、Excel（.xls/.xlsx）
- 网页类：HTML（.html/.htm）
- 文本类：TXT、Markdown、CSV、JSON、XML
- 压缩包：ZIP（会自动解压并处理内部文件）

---

## 系统特性

ModxAI Studio 的 RAG 系统采用了多项技术来提升检索质量：

### 智能文档结构解析

系统会自动识别文档的章节结构（如 Markdown 标题层级），将文档按逻辑单元切分，而非简单的固定长度切割。这确保了：
- 每个文本块包含完整的语义信息
- 保留章节标题与内容的关联关系
- 支持按章节层级配置合并策略

### 多维度检索增强

检索时系统会综合运用多种策略来提高准确率：

| 增强策略 | 说明 |
|---------|------|
| **向量语义检索** | 使用 Embedding 模型理解问题语义，找到含义相近的内容 |
| **章节标题匹配** | 当问题中的关键词出现在章节标题中时，相关内容会获得更高的排序权重 |
| **AI 摘要匹配** | 利用本地 AI 生成的内容摘要进行关键词匹配，弥补语义检索的盲区 |
| **章节聚合排序** | 同一章节被多次命中时，该章节的整体相关性会被提升 |
| **上下文扩展** | 自动补充命中内容的相邻段落，提供更完整的上下文 |
| **重排序优化** | 使用专用的 Rerank 模型对候选结果进行精细排序 |

### 可选的 AI 分析增强

系统提供可选的 AI 分析步骤，可以为每个文本块生成简洁的内容摘要。这些摘要会在检索时参与匹配计算，帮助系统更准确地理解内容主题。

---

## 处理流程

RAG 数据处理包含 8 个步骤，其中 2 个为可选的 AI 增强步骤：

| 步骤编号 | 名称 | 说明 | 必选 | 可配置 |
|------|------|------|------|--------|
| 0 | 转换 | 解析各类文件格式，提取纯文本内容 | ✓ | - |
| 1 | 清洗 | 清理无效内容，去除噪音数据 | ✓ | ✓ |
| 2 | 拆分 | 按章节结构切分文档，生成文本块 | ✓ | ✓ |
| 3 | 分析 | 数据质量分析，去重与复杂度分组 | ✓ | - |
| 4 | AI 合成 | （可选）使用 AI 为文本块生成摘要 | - | ✓ |
| 5 | AI 解析 | （可选）解析并整合 AI 生成的数据 | - | - |
| 11 | 生成向量 | 使用向量模型将文本转换为向量 | ✓ | ✓ |
| 12 | 存储向量 | 将向量数据写入向量数据库 | ✓ | ✓ |

**关于可选步骤**：
- 步骤 4-5 为 AI 增强步骤，需要加载聊天模型
- 跳过这两步不影响基本的向量检索功能
- 启用后可以提升检索的准确性，但会增加处理时间

---

## 各步骤详解

### 步骤 0：转换

**作用**：读取您选择的文件，将 PDF、Word、HTML 等各种格式统一转换为Markdown纯文本。

**处理内容**：
- PDF：提取文字内容，保留段落结构
- Word/PPT/Excel：读取文档内容和表格数据
- HTML：清除标签，保留正文
- 压缩包：自动解压并递归处理内部文件

**说明**：此步骤为自动处理，无需配置参数。

---

### 步骤 1：清洗

**作用**：清理文档中的无效内容，提高数据质量。

**处理内容**：
- 去除页眉页脚、导航栏等重复性内容
- 清理特殊符号和乱码
- 过滤过短的无意义段落

#### 可配置参数

| 参数 | 说明 | 默认值 | 建议 |
|------|------|--------|------|
| **最小段落长度** | 低于此字符数的段落将被过滤 | 3 | 根据内容类型调整，技术文档可设置更大值 |
| **样本作用范围** | 清洗规则的应用范围 | 结构 | `结构` - 只清理页眉页脚等结构区域<br>`全文` - 对全文应用清洗规则 |
| **噪声短语匹配模式** | 清洗样本的匹配模式 | plain | plain=前缀匹配；wildcard=支持*通配；regex=正则匹配 |
| **噪声样本** | 自定义需要清除的内容 | 空 | 用 `\|` 分隔多个样本，如：`关于我们`<br>建议每个样本不超过 20 个字符 |
| **链接行删除级别** | 含链接行的删除级别 | 2 | 0=不删除；1=删除本地/私有路径；2=删除所有链接 |

**高级参数（折叠）**：

| 参数 | 说明 | 默认值 | 建议 |
|------|------|--------|------|
| **清理私有IP链接** | 是否清理包含私有IP的URL行 | 开启 | 建议开启，避免泄露内网地址 |
| **保留富文本链接行** | 含链接但内容丰富的行是否保留 | 关闭 | 开启可保留有价值的引用说明 |
| **脱敏代码块URL** | 是否将代码块中URL替换为[REDACTED_URL] | 关闭 | 根据安全需求决定 |
| **富文本词数阈值** | 判断富文本的词数阈值 | 12 | 用于判断是否保留含链接行 |
| **富文本长度阈值** | 判断富文本的字符长度阈值 | 80 | 配合词数阈值综合判断 |

**使用建议**：
- 如果文档来源单一（如公司内部文档），可以添加统一的页脚信息作为清洗样本
- 技术文档建议将最小段落长度设为 5-10，避免过滤掉代码注释

---

### 步骤 2：拆分

**作用**：将长文档切分为适合检索的文本块（Chunk）。这是 RAG 系统的关键步骤，直接影响检索效果。

**智能拆分逻辑**：
- 自动识别前置步骤转换的 Markdown 标题层级（#、##、### 等）
- 按章节结构进行逻辑切分，保持内容完整性
- 支持配置标题合并级别，控制切分粒度
- 自动过滤导航链接列表、API 函数列表等噪音内容
- 超长章节会按段落和句子边界进一步拆分

#### 章节结构保留

拆分后的每个文本块会记录其所属的章节信息：
- **章节 ID**：唯一标识该章节
- **章节标题**：原始文档中的标题文本
- **层级关系**：标题的嵌套层级

这些信息会在检索时用于章节聚合和上下文扩展。

#### 可配置参数

| 参数 | 说明 | 默认值 | 建议 |
|------|------|--------|------|
| **最小段落长度** | 拆分时保留的最小段落字符数 | 3 | 过小会产生碎片化内容 |
| **最小文档长度** | 文档最少需要的 Token 数 | 10 | 过短的文档将被过滤 |
| **最小块长度** | 单个文本块的最小 Token 数 | 15 | 建议 15-50，过小影响检索质量 |

**Token 说明**：Token 是模型处理文本的基本单位，中文约 1 个字 ≈ 1-2 个 Token，英文约 1 个单词 ≈ 1-3 个 Token。

**使用建议**：
- 问答场景：最小块长度设为 30-50，确保每个块包含完整信息
- 长文档检索：可以适当增大块长度，提高上下文完整性

---

### 步骤 3：分析

**作用**：对处理后的数据进行质量分析，识别重复和异常内容，并按内容复杂度分组。

**处理内容**：
- **近重复检测**：找出高度相似的文本块，保留代表性内容
- **离群点检测**：识别与主题偏离较大的异常内容
- **复杂度分组**：将内容按高/中/低复杂度分类存储

#### 嵌入模型依赖

此步骤的近重复检测功能支持使用嵌入模型来提高检测准确度。系统默认使用 `all-MiniLM-L6-v2` 模型：

- **本地优先**：系统会优先尝试加载本地已下载的模型
- **自动降级**：如果嵌入模型不可用，会自动使用 TF-IDF 算法进行检测
- **可选配置**：您可以在模型库中下载该嵌入模型，或使用其他兼容的 Sentence Transformer 模型

**说明**：此步骤为自动处理，无需配置参数。嵌入模型为可选项，不影响基本功能。

---

### 步骤 4-5：AI 分析（可选）

**作用**：使用 AI 模型为每个文本块生成简洁的内容摘要，用于增强后续的检索效果。

**工作原理**：
1. 系统将每个文本块发送给已加载的聊天模型
2. AI 分析内容并生成默认不超过 50 字符的核心摘要
3. 摘要会与原始文本一起存储到向量数据库中
4. 检索时，系统会同时匹配原文和摘要，提高召回率

**适用场景**：
- 文档内容专业性强，需要提炼核心概念
- 问答时用户的表述方式与文档差异较大
- 希望提高检索的准确性和相关性

#### 可配置参数

| 参数 | 说明 | 默认值 | 建议 |
|------|------|--------|------|
| **系统提示词** | AI 生成摘要时使用的指令 | 内置模板 | 可根据文档领域自定义 |

**注意事项**：
- 此步骤需要先加载聊天模型
- 处理时间与文本块数量成正比
- 跳过此步骤不影响基本检索功能

---

### 步骤 11：生成向量

**作用**：使用向量模型（Embedding Model）将文本块转换为高维向量，这是实现语义检索的核心步骤。

**工作原理**：向量模型将文本的"含义"转换为数学向量，语义相近的内容在向量空间中距离也相近，这使得 AI 能够找到与问题含义相关的内容，而非仅仅匹配关键词。

#### 可配置参数

| 参数 | 说明 | 默认值 | 建议 |
|------|------|--------|------|
| **向量模型** | 选择用于生成向量的模型 | 需手动选择 | 必须从模型库中选择已导入的向量模型（Embedding 类型） |
| **向量归一化** | 是否对向量进行归一化处理 | 开启 | 建议保持开启，可提高检索效果 |

**模型选择建议**：
- 中文为主：选择支持中文的模型，如 `qwen3-embedding`、`bge-large-zh`、`m3e-base`
- 英文为主：可选择 `bge-large-en`、`e5-large`
- 多语言混合：选择多语言模型，如 `bge-m3`

**向量归一化说明**：归一化后的向量长度统一为 1，便于使用余弦相似度进行检索比较。建议保持开启。

---

### 步骤 12：存储向量

**作用**：将生成的向量和对应文本存储到向量数据库中，以便后续检索使用。

**存储内容**：
- 文本向量（用于语义检索）
- 原始文本内容（用于返回结果）
- 章节结构信息（用于聚合和上下文扩展）
- AI 摘要（如果启用了步骤 4-5）
- 其他元数据（文件名、块索引等）

#### 可配置参数

| 参数 | 说明 | 默认值 | 建议 |
|------|------|--------|------|
| **集合名称** | 向量库的标识名称 | 自动生成 | 建议使用有意义的名称，如 `产品手册_v1`、`技术文档` |
| **目标维度** | 向量的维度大小 | 1024 | 需与模型输出维度匹配，通常不需修改 |
| **向量池化策略** | 多维向量的合并方式 | mean | 高级选项，一般保持默认 |

**集合名称说明**：
- 集合名称是知识库的唯一标识，在聊天时用于选择要检索的知识库
- 建议使用简洁明了的命名，便于识别和管理
- 同名集合的新数据会追加到现有集合中

**池化策略说明**（高级选项）：
- `mean`：平均池化，综合所有特征，最常用
- `max`：最大池化，保留最显著特征
- `cls`：使用首位置的特征向量

---

## 输出与存储

### 中间文件

处理过程中的数据按步骤存储在输出目录：

```
输出目录/
├── ori/              # 步骤 0：原始解析数据
├── opt1/             # 步骤 1：清洗后数据
├── opt2/             # 步骤 2：拆分后数据（含章节结构）
├── opt3/             # 步骤 3：分析后数据
│   ├── high_complexity/
│   ├── mid_complexity/
│   └── low_complexity/
├── opt4/             # 步骤 4：AI 分析数据（可选）
├── opt5/             # 步骤 5：AI 解析后数据（可选）
└── rag_dataset/      # 向量数据库存储
    ├── embeddings/   # 向量文件
    └── storage/      # Qdrant 数据库文件
```

### 向量数据库

最终的向量数据存储在**独立的向量数据库**中，而非应用的本地数据库：

- **存储位置**：输出目录下的 `rag_dataset/storage` 文件夹
- **数据库类型**：Qdrant 向量数据库（本地模式）
- **数据格式**：向量 + 原始文本 + 元数据（含章节信息和可选摘要）

**重要说明**：
- 向量数据库与中间处理文件分开存储
- 每个集合按向量维度自动分组，例如 `产品手册_1024d`
- 向量数据库包含完整的检索所需信息，无需保留中间文件

---

## 在聊天中使用

完成 RAG 数据处理后，可以在聊天中启用知识库检索：

1. **打开参数设置**：在聊天界面点击参数抽屉
2. **选择知识库**：在 RAG 配置区域选择已创建的集合
3. **配置检索模式**：选择合适的检索方式（见下方说明）
4. **开始对话**：AI 会自动检索相关内容辅助回答

### 检索模式

系统支持多种检索模式，可在聊天参数中选择：

| 模式 | 说明 | 适用场景 |
|------|------|----------|
| **混合模式 (hybrid)** | 向量检索 + 重排序 + 多维度增强 | **推荐**，综合效果最佳 |
| **向量模式 (vector)** | 仅使用向量语义检索 | 快速检索，不需要加载 Rerank 模型 |
| **文本模式 (text)** | 传统的关键词检索 | 兜底方案，不需要向量模型 |
| **重排序模式 (rerank)** | 向量检索 + Rerank 精排 | 需要加载 Rerank 模型 |

**重排序模型**：如果希望使用混合模式或重排序模式，建议在模型库中导入 Rerank 类型的模型（如 `qwen3-reranker`）并加载。

### 管理知识库

- **查看列表**：在参数抽屉中可以看到所有可用的知识库集合
- **删除集合**：点击集合旁的删除按钮可移除知识库
- **删除注意**：删除操作仅移除集合配置，**不会删除已存储的向量数据文件**
- **重新导入**：支持重新导入已删除的集合，前提是向量数据文件仍然存在

---

## 从收藏数据导出

除了直接处理文档，您还可以将聊天中积累的收藏数据导出为 RAG 格式：

### 操作步骤

1. **进入收藏数据管理**：在聊天界面点击"收藏"按钮
2. **选择导出数据**：勾选要导出的对话或点赞内容
3. **选择导出格式**：选择"RAG 知识库格式"
4. **配置导出选项**：设置名称等参数
5. **执行导出**：导出后需从(**生成向量**)步骤开始完成后续处理

### 使用场景

- 将高质量的 AI 回答积累为知识库
- 基于历史对话构建专属问答库
- 将点赞的优质内容转化为可检索知识

---

## 注意事项

### 环境要求

| 要求 | 说明 |
|------|------|
| **环境** | 必须在**设置**中安装环境才能运行向量模型 |
| **向量模型** | 必须在模型库中导入至少一个 Embedding 类型的模型 |
| **重排序模型**（可选） | 建议导入 Rerank 类型模型以获得更好的检索效果 |
| **聊天模型**（可选） | 启用 AI 分析步骤需要加载聊天模型 |
| **磁盘空间** | 向量数据库会占用一定存储空间，请确保输出目录有足够空间 |

### 配额消耗

RAG 数据处理会消耗免费配额：
- 步骤 0（转换）：免费
- 步骤 1-3, 11-12：每处理/生成一条数据记录消耗 1 个配额单位
- 步骤 4-5（AI 分析）：每条数据消耗对应的 AI 生成配额

### 性能建议

- **首次处理**：大量文档首次处理可能需要较长时间，建议先用少量文件测试
- **增量更新**：支持增量处理，新增文件无需重新处理全部数据
- **GPU 加速**：如果有 GPU，向量生成速度会显著提升
- **AI 分析**：步骤 4-5 的处理时间取决于聊天模型的推理速度

---

## 常见问题

**Q：向量模型应该选择哪个？**

A：根据您的内容语言选择：
- 纯中文内容：推荐 `qwen3-embedding`、`bge-large-zh` 或 `m3e-base`
- 纯英文内容：推荐 `qwen3-embedding`、`bge-large-en` 或 `e5-large`
- 中英混合：推荐 `qwen3-embedding`、`bge-m3` 多语言模型

**Q：需要使用 AI 分析步骤吗？**

A：视情况而定：
- 如果文档结构清晰、标题明确，基本的向量检索已经足够
- 如果文档专业性强或用户提问方式多样，建议启用 AI 分析以提高准确率
- AI 分析会增加处理时间，可以先不启用，根据实际检索效果再决定

**Q：处理失败如何排查？**

A：常见原因：
1. 未在**设置**中安装环境 - 请在**设置**中进行配置
2. 未导入向量模型 - 请先在模型库导入 Embedding 类型模型
3. 配额不足 - 检查剩余配额或等待重置
4. AI 分析步骤失败 - 检查聊天模型是否已加载

**Q：可以修改已有知识库的内容吗？**

A：目前不支持直接编辑。如需更新，建议：
1. 删除旧集合
2. 修改源文档后重新处理
3. 或使用新的集合名称创建更新版本

**Q：删除聊天中的知识库会影响数据吗？**

A：在聊天参数抽屉中删除知识库集合，只是取消关联，**不会删除实际的向量数据文件**。如需彻底删除，需要手动清理输出目录中的向量存储文件。

**Q：检索效果不理想怎么办？**

A：可以尝试以下优化：
1. 确保使用混合检索模式并加载 Rerank 模型
2. 启用 AI 分析步骤（步骤 4-5）
3. 调整文本块大小，避免过小的碎片化内容
4. 检查清洗步骤是否误删了有价值的内容
5. 尝试更换向量模型

**Q：集合名称可以使用中文吗？**

A：建议使用英文或拼音命名，中文可能在某些系统环境下导致兼容性问题。

---

## 后续文档

- [数据处理概述](./overview.md) - 了解数据处理模块的整体架构
- [SFT 数据处理](./sft.md) - 用于模型微调的数据集生成
- [音频转文本](./audio2text.md) - 音频转录功能详细指南
